# SLRKIT command
The `slrkit` command helps to handle a slr-kit project.
This command automates and handles all the phases of the document analysis.
To do so, a set of configuration files are used in order to automate the process.
These files are stored in a slr-kit project and are created and managed by the `slrkit` command itself.

## SLR-KIT projects

An SLR-KIT project is a collection of files generated by the SLR-KIT scripts.
All of these files, are generated from a set of documents that the user wishes to analyze.
A project is also a `git` repository.
The `slrkit` command initializes this repository when the project is first created and helps to track only the meaningful files.

### Anathomy of a project
An SLR-KIT project is a directory that contains all the files related to an analysis.
This directory must contain also a `META.toml` file and a project configuration directory.

#### META.toml
This file contains all the metadata about the project.
It must be a [TOML version 1.0.0](https://toml.io/en/v1.0.0) file.
It must contain two dictionaries: `Project` and `Source`.

##### `Project` dictionary
This contains information about the project such as the name of the project, a description, the location of the configuration directory and some more.
The allowed keys and their meaning are described in the following table:

| Key         | Description                                 | Type            |
|-------------|---------------------------------------------|:---------------:|
| Author      | Information about the author of the project |      string     |
| Config      | Name of the configuration directory         |      string     |
| Description | Description of the project                  |      string     |
| Keywords    | List of keywords related to the documents   | list of strings |
| Name        | Name of the project                         |      string     |

##### `Source` dictionary
This contains information about the source of the documents analyzed in the project.
The allowed keys and their meaning are described in the following table:

| Key    | Description                                    | Type   |
|--------|------------------------------------------------|:------:|
| URL    | URL of the site used to retrieve the documents | string |
| Query  | Query string usedto retrieve the documents     | string |
| Date   | Date on which the documents were retrieved     | string |
| Origin | Description of the origin of the documents     | string |

The `Origin` key is meant to be used when the documents are retrieved without the help of a bibligraphical search engine.
In this case the `URL` and `Query` keys shall be left empty.

#### The project configuration directory
This directory is located inside the project directory.
Its name is saved in the `META.toml` file in the `Project.Config` key.
The default name for this directory is `slrkit.conf` but a different name may be used.
This directory contains all the configuration files used by the project.
The configuration files must be TOML v. 1.0.0 files.
Information about each file can be found in the documentation of each `slrkit` subcommand.
Each relative path included in the configuration files are considered to be relative to the project root directory.
The configuration directory contains also a `log` directory that contains all the log files produced during the project.
All the scripts that write a log use the `slr-kit.log` log file saved in the log directory.

## The `slrkit` command
The `slrkit` command is the tool to handle a project.
It uses the `META.toml` and the file in the project configuration directory to automate the operations.
It is composed by some sub-commands to handle and automate all the phases of a project.

Usage:

    python3 slrkit.py [-C /path/to/project] sub-command sub-command-arguments ...

The sub-commands are:

* `init`: initialize a slr-kit project
* `import`: import a bibliographic database converting to the csv format used by slr-kit.
* `journals`: subcommand to extract and filter a list of journals. Requires a subcommand.
* `acronyms`: extract acronyms from texts.
* `preprocess`: run the preprocess stage in a slr-kit project
* `terms`: subcommand to extract and handle lists of terms in a slr-kit project. Requires a sub-command
* `fawoc`: run fawoc in a slr-kit project.
* `lda`: run the lda stage in a slr-kit project
* `report`: run the report creation script in a slr-kit project.
* `optimize_lda`: run an optimization phase for the lda stage in aslr-kit project, using a GA.
* `record`: record a snapshot of the project in the underlying git repository
* `lda_grid_search`: run an optimization phase for the lda stage in a slr-kit project using a grid search method.

Each command operates on the directory from which the `slrkit` command is run.
The `-C` option allows to change the current directory to the one specified.

### init
Initialize the current directory as an SLR-KIT project.
Usage:

    python3 slrkit.py init [--author AUTHOR] [--description DESCRIPTION] [--no-backup] name

Argument `name` is the name of the project.
It will be used as a prefix for all the suggested file names.
The `--author` option allows to specify the project author while the `--description` option allows to specify the project description.
It creates the `META.toml` files with information from the command line.
**The user shall complete the content of this file**.

This command also creates the configuration directory.
This directory is populated with all the configuration files handled by the `slrkit` command.
The file format is [TOML version 1.0.0](https://toml.io/en/v1.0.0).
The name of each file is the name of the `slrkit` sub-command (e.g. `preprocess.toml` is the configuration file for the `slrkit preprocess` command) and it contains a key for each parameter of the corresponding script.
Refer to the documentation of each script for additional information about the configuration parameters.
In each file some comments explain each parameter, and the output file name of each script are suggested with some good default names.

This command can be executed on an already initialized project.
In this case the information in the `META.toml` are updated with the ones given on the command line.
All the other fields are left untouched.
The configuration files are updated.
If one or more option are missing, they are filled with the default value.
The other information are not changed.
The original `toml` files are backuped in the configuration directory before any modification.
The backups have the same name of the original files with the extension `.bak`.
If the user gives the `--no-backup` option, no backup is performed.

The `init` sub-command also initializes the `git` repository of the project.
A `.gitignore` file is provvided with some useful patterns.
A first commit is recorded with:

* the `META.toml` file;
* all the configuration files;
* the provvided `.gitignore`.

### import
This command imports a bibliographical database into the project, converting it to the `Â¢sv` format used by all the scripts.
The output of this command will be called the *abstracts* file in the rest of this document.

Usage:

    python3 slrkit.py import [--list_columns]

The `import` sub-command uses the `import.toml` configuration file and runs the `import_biblio.py` script.
It imports the database in a `csv` usable by the other commands.
To each paper is assigned a progressive identification number in the column `id`.
All the selected columns are imported from the input file.
The citation count for each paper is also retrived and imported as the column `citation`.
If the option `--list_columns` is set, the command outputs only the list of available columns of the input file specified in the configuration file and no data is imported.

After a correct execution, the command changes `journals_extract.toml`, `journals_filter.toml` and `report.toml` files updating their `ris_file` field with the name of the input file.

The `import.toml` has the following structure:

* `input_file`: path to the bibliographical database to import. **Important:** this field is not pre-filled by the `init` command, the user **must** fill it before running the `import` command. This file is committed to `git` repository by the `record` command;
* `type`: type of the database to import. Actually the only supported type is `RIS`;
* `output`: name of the output file. It is pre-filled with `<project-name>_abstracts.csv`;
* `columns`: comma separed list of columns to import. It is pre-filled with `title,abstract,year`. Additionally, a `citation` column is also imported by default.

### journals
This command allows the user to retrieve a list of journals and classify them in order to filter out the not relevant ones and the papers published on them.

This command accepts two sub-commands:

* `extract`: extracts the list of journals from the bibliographical database;
* `filter`: uses the manual classification of the list of journals to filter out the papers published on the not relevant journals.

Usage:

    python3 slrkit.py journals {extract, filter}

If the `journals` command is invoked without a sub-command, the `extract` sub-command is run.

#### journals extract
The `extract` sub-command produces a list in the format used by `FAWOC`.
The structure is the following:

* `id`: a progressive identification number;
* `term`: the name of the journal;
* `label`: the label added by `FAWOC` to the journal. This field is left blank by the `extract` sub-command;
* `count`: the number of papers pubblished in the journal.

`FAWOC` will move the count field in the `fawoc_data.tsv` file.

The `extract` sub-command uses the `journals_extract.toml` configuration file and runs the `journal_lister.py` script.
The `journals_extract.toml` file has the following structure:

* `ris_file`: name of the bibliographical database. It is pre-filled with `<project-name>.ris` and is updated by the `import` command;
* `outfile`: name of the output file. It is pre-filled with `<project-name>_journals.csv`.


#### journals filter
The `filter` sub-command filters the papers using the manual classification of the list of journals.
It adds the `status` column to the *abstracts* file.
This column will have the value `good` for the papers published in a journal classified with `relevant` or the `keyword` label.
All the papers from journals not classified as `relevant` or `keyword` will be marked with the `rejected` value in the `status` column.

The `filter` sub-command uses the `journals_filter.toml` configuration file and runs the `filter_paper.py` script.
The `journals_filter.toml` file has the following structure:

* `ris_file`: name of the bibliographical database. It is pre-filled with `<project-name>.ris` and is updated by the `import` command;
* `abstract_file`: name of the *abstract* file. It is pre-filled with `<project-name>_abstracts.csv`;
* `journal_file`: name of the journal list file produced by `journal extract`. It is pre-filled with `<project-name>_journals.csv`.

### acronyms
This commands extracts acronyms from the papers.
Its output format is suitable to be used with `FAWOC` to classify which acronym is relevant or not.
If the input file (the *abstract* file) contains the `status` column created by the `journals filter` command, the `acronyms` command uses that column value to filter out the paper pubblished in the rejected journals.
The output of this command will be called the *acronyms* file in the rest of this document.

Usage:

    python3 slrkit.py acronyms

The `acronyms` sub-command uses the `acronyms.toml` configuration file and runs the `acronyms.py` script.
The output is in `tsv` format and has the following structure (suitable for `FAWOC`):

* `id`: a progressive identification number;
* `term`: the acronym in the form `extended-acronym | (abbreviation)`;
* `label`: the label added by `FAWOC` to the acronym. This field is left blank by the `acronyms` command.

No `fawoc_data` file is produced, so no `count` field is available for `FAWOC`.

After a correct execution, the command changes the `preprocess.toml` file updating its `acronyms` field with the name of the output file.
All the commands consider only the acronyms classified with the `relevant` or the `keyword` label.
All the other acronyms are not considered.

The `acronyms.toml` has the following structure:

* `datafile`: input file. It is pre-filled with the value `<project-name>_abstracts.csv`;
* `output`: output file. It is pre-filled with the value `<project-name>_acronyms.csv`;
* `columns`: name of the column of `datafile` with the text to elaborate. It is prefilled with the value `abstract`.


### preprocess
The `preprocess` sub-command prepares the documents for the following elaborations.

Usage:

    python3 slrkit.py preprocess

If the input file (the *abstract* file) contains the `status` column created by the `journals filter` command, the `preprocess` command uses that column value to filter out the paper pubblished in the rejected journals.
It also filters the stop-words using the list of words providded by the user.
No default list of stop-words is used, the user **must** provvide his own lists.

This command also uses the *acronyms* file to search and mark the acronyms as relevant words.
Only the acronyms with the `relevant` or the `keyword` label are considered.

The `preprocess` command, also mark as relevant all the terms provvided by the user in the relevant terms lists.
The user can also choose how the command marks this terms.
The input of this command is the *abstract* file.
The output of this command is the *abstract* file without the paper discarded because pubblished in rejected journals.
To this file is also added a new column with the text of each paper preprocessed.
More information can be found in the preprocess.py section of the [README.md](README.md) 

The `preprocess` sub-command uses the `preprocess.toml` configuration file.
This file has the following structure:

* `datafile`: the name of the *abstract* file that will be used as input. This field is pre-filled with `<project-name>_abstracts.csv`;
* `output`: output file name. This field is pre-filled with `<project-name>_preproc.csv`;
* `placeholder`: placeholder used to mark the barriers (the stop-words and the punctuaction). This character is also used as prefix and suffix for the placeholder for the relevant terms and the acronyms. It is prefilled with the character `@`;
* `stop-words`: lists of stop-words provvided by the user. No other lists are used, so the user shall provvide its own;
* `relevant-term`: lists of relevant terms. This field is particular. Each element must be a list of at least one item and at most two items. The first item is the name of a list of relevant terms. The second one, if present, is the marker that the user want to be used for all the terms in this list. All the terms will be marked with `<placeholder><marker><placeholder>`. If the marker is ommitted than the command replaces every term using the placeholder, all the words of the term separed with `_` character and then another placeholder;
* `acronyms`: name of the *acronyms* file. If the `acronyms` command is run before, it is pre-filled with `<project-name>_acronyms.csv`;
* `target-column`: name of the column used for the document text. It is pre-filled with `abstract`;
* `output-column`: name of the column that is added to the output, containing the preprocessed text. It is pre-filled with `abstract_lem`;
* `input-delimiter`: input file field delimiter. It is pre-filled with `\t`;
* `output-delimiter`: input file field delimiter. It is pre-filled with `\t`;
* `rows`: number of rows of the input file to process. If empty, all the rows are used;
* `language`: language of text. Must be a ISO 639-1 two-letter code. Pre-filled with `en`;
* `regex`: csv file with some dataset specific regex substitutions that has to be applied to the text.

The output of this command will be called the *preprocess* file in the rest of this document.

### terms
This command allows the user to generate and handle lists of terms.

This command accepts one sub-command:

* `generate`: generate a list of terms that have to be classified.

Usage:

    python3 slrkit.py terms {generate}

If the `terms` command is invoked without a sub-command, the `generate` sub-command is run.

#### terms generate
The `generate` sub-command generates a list of terms from the documents in the *preprocess* file.
This command runs the `gen_terms.py` script.
The format of this list is the one used by `FAWOC`. The structure is the following:

* `id`: a progressive identification number;
* `term`: the n-gram;
* `label`: the label added by `FAWOC` to the n-gram. This field is left blank by the `terms generate` command.

This command produces also the `fawoc_data.tsv` file, with the following structure:

* `id`: the identification number of the term;
* `term`: the term;
* `count`: the number of occurrences of the term.

The output of this command will be called the *terms* file in the rest of this document.

The `terms generate` sub-command uses the `terms_generate.toml` configuration file.
It has the following structure:

* `datafile`: name of the input file (the *preprocess* file). It is pre-filled with `project-name>_preproc.csv`;
* `output`: name of the output file. It is prefilled with `<project-name>_terms.csv`;
* `stdout`: if `true` the command also print the output to the standard output;
* `n-grams`: maximum size of an n-gram. All the n-gram with lengths from one word to this number of words are generated. By default, this field is filled with `4`;
* `min-frequency`: minimum number of occurrences of an n-gram. All the n-gram with less occurrences than this value are discarded. Pre-filled with `5`;
* `placeholder`: placeholder used to mark the barriers in the `preprocess` stage. All the n-grams containg this character or containing words that start and end with this character are discarded. It is prefilled with the character `@`;
* `column`: column of the input file with the text to elaborate. Pre-filled with `abstract_lem`;
* `delimiter`: field delimiter used by the input file. Pre-filled with `\t`.

### lda
The `lda` sub-command uses the `lda.toml` configuration file and runs the `lda.py` script.

### lda_grid_search
The `lda_grid_search` sub-command uses the `lda_grid_search.toml` configuration file and runs the `lda_grid_search.py` script.

### fawoc
The `fawoc` sub-command uses the `fawoc.toml` configuration file and runs the `fawoc` tool.
The profiler file is saved in the `log` directory inside the configuration directory.
The profiler is called `fawoc_profiler.log`.
